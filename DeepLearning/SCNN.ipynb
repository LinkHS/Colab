{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgr4iwi29BqOKo+qRfTDFP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeZw1rz9FM-R"
      },
      "source": [
        "https://github.com/harryhan618/SCNN_Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6wpsA75_q0l"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import jdc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whBP3rWc_tlb"
      },
      "source": [
        "class SCNN(nn.Module):\n",
        "  def __init__(self, input_size, ms_ks=9, pretrained=True):\n",
        "    \"\"\"\n",
        "    Argument\n",
        "      ms_ks: kernel size in message passing conv\n",
        "    \"\"\"\n",
        "    super(SCNN, self).__init__()\n",
        "    self.pretrained = pretrained\n",
        "    self.net_init(input_size, ms_ks)\n",
        "    if not pretrained:\n",
        "      self.weight_init()\n",
        "\n",
        "    self.scale_background = 0.4\n",
        "    self.scale_seg = 1.0\n",
        "    self.scale_exist = 0.1\n",
        "\n",
        "    self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor([self.scale_background, 1, 1, 1, 1]))\n",
        "    self.bce_loss = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du5bwcqCBIWn"
      },
      "source": [
        "%%add_to SCNN\n",
        "def weight_init(self):\n",
        "  for m in self.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "      m.reset_parameters()\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "      m.weight.data[:] = 1.\n",
        "      m.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MQmtpRAmp6"
      },
      "source": [
        "%%add_to SCNN\n",
        "def net_init(self, input_size, ms_ks):\n",
        "  input_w, input_h = input_size\n",
        "  self.fc_input_feature = 5 * int(input_w/16) * int(input_h/16)\n",
        "  self.backbone = models.vgg16_bn(pretrained=self.pretrained).features\n",
        "\n",
        "  # ----------------- process backbone -----------------\n",
        "  for i in [34, 37, 40]:\n",
        "    conv = self.backbone._modules[str(i)]\n",
        "    dilated_conv = nn.Conv2d(\n",
        "        conv.in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride,\n",
        "        padding=tuple(p * 2 for p in conv.padding), dilation=2, bias=(conv.bias is not None)\n",
        "    )\n",
        "    dilated_conv.load_state_dict(conv.state_dict())\n",
        "    self.backbone._modules[str(i)] = dilated_conv\n",
        "  self.backbone._modules.pop('33')\n",
        "  self.backbone._modules.pop('43')\n",
        "\n",
        "  # ----------------- SCNN part -----------------\n",
        "  self.layer1 = nn.Sequential(\n",
        "    nn.Conv2d(512, 1024, 3, padding=4, dilation=4, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(1024, 128, 1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU()  # (nB, 128, 36, 100)\n",
        "  )\n",
        "\n",
        "  # ----------------- add message passing -----------------\n",
        "  self.message_passing = nn.ModuleList()\n",
        "  self.message_passing.add_module('up_down', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
        "  self.message_passing.add_module('down_up', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
        "  self.message_passing.add_module('left_right', nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
        "  self.message_passing.add_module('right_left', nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
        "  # (nB, 128, 36, 100)\n",
        "\n",
        "  # ----------------- SCNN part -----------------\n",
        "  self.layer2 = nn.Sequential(\n",
        "    nn.Dropout2d(0.1),\n",
        "    nn.Conv2d(128, 5, 1)  # get (nB, 5, 36, 100)\n",
        "  )\n",
        "\n",
        "  self.layer3 = nn.Sequential(\n",
        "    nn.Softmax(dim=1),  # (nB, 5, 36, 100)\n",
        "    nn.AvgPool2d(2, 2),  # (nB, 5, 18, 50)\n",
        "  )\n",
        "  self.fc = nn.Sequential(\n",
        "    nn.Linear(self.fc_input_feature, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 4),\n",
        "    nn.Sigmoid()\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tbWVCmgAifO"
      },
      "source": [
        "%%add_to SCNN\n",
        "def forward(self, img, seg_gt=None, exist_gt=None):\n",
        "  x = self.backbone(img)\n",
        "  x = self.layer1(x)\n",
        "  x = self.message_passing_forward(x)\n",
        "  x = self.layer2(x)\n",
        "\n",
        "  seg_pred = F.interpolate(x, scale_factor=8, mode='bilinear', align_corners=True)\n",
        "  x = self.layer3(x)\n",
        "  x = x.view(-1, self.fc_input_feature)\n",
        "  exist_pred = self.fc(x)\n",
        "\n",
        "  if seg_gt is not None and exist_gt is not None:\n",
        "    loss_seg = self.ce_loss(seg_pred, seg_gt)\n",
        "    loss_exist = self.bce_loss(exist_pred, exist_gt)\n",
        "    loss = loss_seg * self.scale_seg + loss_exist * self.scale_exist\n",
        "  else:\n",
        "    loss_seg = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "    loss_exist = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "    loss = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "  return seg_pred, exist_pred, loss_seg, loss_exist, loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB5b8Kj7BvQe"
      },
      "source": [
        "%%add_to SCNN\n",
        "def message_passing_forward(self, x):\n",
        "  Vertical = [True, True, False, False]\n",
        "  Reverse = [False, True, False, True]\n",
        "  for ms_conv, v, r in zip(self.message_passing, Vertical, Reverse):\n",
        "    x = self.message_passing_once(x, ms_conv, v, r)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrHXuQ62Bovk"
      },
      "source": [
        "%%add_to SCNN\n",
        "def message_passing_once(self, x, conv, vertical=True, reverse=False):\n",
        "  \"\"\"\n",
        "  Argument:\n",
        "  ----------\n",
        "  x: input tensor\n",
        "  vertical: vertical message passing or horizontal\n",
        "  reverse: False for up-down or left-right, True for down-up or right-left\n",
        "  \"\"\"\n",
        "  nB, C, H, W = x.shape\n",
        "  if vertical:\n",
        "    slices = [x[:, :, i:(i + 1), :] for i in range(H)]\n",
        "    dim = 2\n",
        "  else:\n",
        "    slices = [x[:, :, :, i:(i + 1)] for i in range(W)]\n",
        "    dim = 3\n",
        "  if reverse:\n",
        "    slices = slices[::-1]\n",
        "\n",
        "  out = [slices[0]]\n",
        "  for i in range(1, len(slices)):\n",
        "    out.append(slices[i] + F.relu(conv(out[i - 1])))\n",
        "  if reverse:\n",
        "    out = out[::-1]\n",
        "  return torch.cat(out, dim=dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlCYXUmjB933"
      },
      "source": [
        "scn = SCNN((224,224), pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isoilPMuD3ps",
        "outputId": "e9c99a93-c6cc-443d-f4ea-cff55b96409d"
      },
      "source": [
        "scn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SCNN(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              "  (message_passing): ModuleList(\n",
              "    (up_down): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
              "    (down_up): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
              "    (left_right): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
              "    (right_left): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Dropout2d(p=0.1, inplace=False)\n",
              "    (1): Conv2d(128, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Softmax(dim=1)\n",
              "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=980, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=4, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              "  (ce_loss): CrossEntropyLoss()\n",
              "  (bce_loss): BCELoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}